# $t@$h
# This program does NOT modify your system in any way
# Uses ensemble learning to detect embedded nim files
# Working on ways to improve detection. See comments at
# the bottom for the play by play. Naive bayes + decision tree
import os
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Function to read files from a directory
def read_files_from_directory(directory):
    contents = []
    for root, dirs, files in os.walk(directory):
        for file in files:
            try:
                with open(os.path.join(root, file), 'r', encoding='utf-8', errors='ignore') as f:
                    contents += f.readlines()
            except Exception as e:
                print(f"Error reading {file}: {e}")
    return contents

# Replace these with your actual directory paths
nim_directory = 'datasets/training/nim'
non_nim_directory = 'datasets/training/non_nim'

nim_samples = read_files_from_directory(nim_directory)
non_nim_samples = read_files_from_directory(non_nim_directory)

# Combining samples and creating labels
samples = nim_samples + non_nim_samples
labels = [1] * len(nim_samples) + [0] * len(non_nim_samples)

# Vectorization
vectorizer = TfidfVectorizer() # TfidfVectorizer(max_features=1000) or other value to improve performance
X = vectorizer.fit_transform(samples)

# Splitting the dataset
X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)

# Define base learners
base_learners = [
    ('dt', DecisionTreeClassifier(random_state=42)), # DecisionTreeClassifier(max_depth=10, random_state=42) or other improve perf
    ('nb', MultinomialNB())
]

# Define meta-learner
meta_learner = LogisticRegression(random_state=42)

# Stacking classifier
stacked_clf = StackingClassifier(estimators=base_learners, final_estimator=meta_learner)

# Train the stacked model
stacked_clf.fit(X_train, y_train)

# Predict and evaluate
y_pred = stacked_clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Model Accuracy: {accuracy:.2%}')

# Function to predict new files
def predict_new_files(model, vectorizer, new_files_directory):
    new_samples = []
    filenames = []
    for root, dirs, files in os.walk(new_files_directory):
        for file in files:
            try:
                with open(os.path.join(root, file), 'r', encoding='utf-8', errors='ignore') as f:
                    new_samples.append(f.read())
                    filenames.append(file)
            except Exception as e:
                print(f"Error reading {file} in {root}: {e}")

    X_new = vectorizer.transform(new_samples)
    predictions = model.predict(X_new)

    return filenames, predictions

new_files_directory = 'datasets/testing'
filenames, predictions = predict_new_files(stacked_clf, vectorizer, new_files_directory)

# Print filenames and their predictions
for filename, pred in zip(filenames, predictions):
    print(f'{filename}: {"Nim" if pred == 1 else "Non-Nim"}')

# Results are:
# stashakkori$ python3 detect.py
# Stacked Model Accuracy: 99.47%
# dijkstra.cpp: Non-Nim
# prime_number.py: Non-Nim
# merge-sort.cpp: Non-Nim
# shellcode_bin.nim: Nim
# quick_sort.py: Non-Nim
# longest-common-subsequence.cpp: Non-Nim
# reverse_string.py: Non-Nim
# excel_com_bin.nim: Nim
# minidump_bin.nim: Nim
# connection.txt: Non-Nim
# prime-number.cpp: Non-Nim
# minimum_spanning_tree.py: Non-Nim
# roman_numeral.py: Non-Nim
# rot13.py: Non-Nim
# selection-sort.cpp: Non-Nim
# main.nim: Non-Nim
# iran_server.nim: Non-Nim
# recorder.nim: Nim
# reverse-string.cpp: Non-Nim
# dns_resolve.nim: Nim
# pipe.nim: Nim
# transpose_matrix.py: Non-Nim
# quick-sort.cpp: Non-Nim
# rot13.txt: Non-Nim
# depth-first-search.cpp: Non-Nim
# palindromic-number.cpp: Non-Nim
# foreign_server.nim: Non-Nim
# globals.txt: Non-Nim
# roman-numeral.cpp: Non-Nim

# Results indicate maybe some overfitting to extension
# As some false negatives such as:
#    foreign_server.nim: Non-Nim (should be Nim)
#    iran_server.nim: Non-Nim (should be Nim)
#    connection.txt: Non-Nim (should be Nim)
# Next steps:
#    1. Add more nim files to nim training data set
#    2. Make all file extensions .txt and retrain
